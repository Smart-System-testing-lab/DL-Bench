# DL-Bench Repository

This README provides detailed information on the purpose and functionality of each file in the DL-Bench repository, which is structured to benchmark and evaluate code generation capabilities of large language models (LLMs) in deep learning projects. Each file in this repository is responsible for specific tasks in the testing and manipulation of functions and classes.

---

## File Descriptions

### 1. `call.py`

This script is primarily responsible for executing tests on individual functions and comparing test results after modifications. The `runner` function is central to this process and follows these steps:
- **Backup**: Creates a backup of the target file.
- **Initial Testing**: Runs initial tests using `pytest` to establish a baseline result.
- **Modification**: Uses the `replace_function` function to temporarily modify the target function, rerunning tests to identify which cases fail with the modification.
- **Restore**: Restores the original function from backup.
- **Final Testing**: Runs the tests once more with the restored function to validate that results match the initial run.
  
This process helps identify test cases affected by function modifications, providing insight into the impact of LLM-generated code changes.

### 2. `parse_code.py`

The `parse_code.py` file processes JSON files containing LLM-generated code and metadata. This script reads LLM outputs, extracts Python code snippets, and executes them within a testing environment. Key steps include:
- **JSON Parsing**: Reads JSON output files generated by LLMs, targeting files with `.json` extensions.
- **Code Extraction**: Uses regex patterns to identify Python code blocks in LLM outputs.
- **Test Execution**: Calls the `runner` function from `call.py` to execute tests on extracted code, capturing any differences in test results compared to the original.
  
This script is integral to the benchmarking pipeline, which evaluates LLM-generated code's accuracy and effectiveness in replicating expected functionality.

### 3. `test_runner_class.py`

`test_runner_class.py` extends the test functionality to class-based methods. This script handles metadata for class names, function names, and test cases associated with specific classes. Key functions include:
- **Class-Specific Testing**: Runs tests on methods within a class and compares results from initial, modified, and restored versions of the code.
- **Comparison**: Identifies which test cases are impacted by modifications to class methods.
  
The script facilitates in-depth testing for LLM-generated code in class contexts, helping determine compatibility and functionality of methods within class structures.

### 4. `test_runner.py`

This script provides functionality similar to `test_runner_class.py`, but is designed for individual (non-class) functions. Main operations include:
- **Test Execution**: Runs initial and modified tests for standalone functions.
- **Result Comparison**: Uses a comparison function to identify changes in test results due to modifications, assisting in isolating test cases affected by LLM code changes.
  
The script plays an essential role in evaluating the accuracy of LLM-generated functions and identifying their functional compatibility within a project.

### 5. `replacer.py`

`replacer.py` is responsible for programmatically replacing functions within a codebase. Key functionalities include:
- **Function Backup**: Backs up the target file to ensure the original function can be restored.
- **Function Wrapping**: Creates a wrapper around an existing function by renaming the original and allowing the new version to import it for isolated testing.
- **AST Manipulation**: Uses Abstract Syntax Trees (ASTs) to find, rename, and modify functions, facilitating code manipulation without changing the underlying logic.
  
The `replace_function` function is particularly useful for testing generated code in isolated contexts while maintaining the original function structure in the codebase.

### 6. `replace_class.py`

Expanding on `replacer.py`, `replace_class.py` introduces functionality for replacing methods within classes. Key features include:
- **Class and Method Identification**: Locates the target class and method within a file and replaces the method with a new definition.
- **AST Operations**: Similar to `replacer.py`, it uses ASTs to perform precise code modifications without altering the surrounding code structure.
- **Backup and Restore**: Backs up the original code and restores it after testing, ensuring modifications are reversible.
  
This file is especially useful for testing new or modified class methods generated by LLMs in deep learning projects, providing flexibility to validate changes within object-oriented contexts.

### 7. `parse_code_class.py`

The `parse_code_class.py` file processes LLM-generated JSON data specifically for classes. It follows these steps:
- **Class-Level JSON Parsing**: Reads LLM-generated JSON output files, specifically targeting class-based functions and methods.
- **Code Extraction and Storage**: Extracts code snippets for methods within classes and saves them temporarily for testing.
- **Test Execution**: Initiates tests using the `runner` function, verifying the functionality of generated methods within the target class structure.
  
This script is tailored for class-based testing, enabling the assessment of LLM-generated class methods against known ground-truth implementations.

---

Each file is integral to the benchmarking and evaluation of code generation by large language models in deep learning projects. By isolating and comparing test results for modified functions and classes, the repository enables robust assessment of LLMs' ability to produce functionally accurate code in real-world settings.
